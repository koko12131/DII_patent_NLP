{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load DII plain text of patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_load_f(input_path):\n",
    "    '''input_path'''\n",
    "    file_path = []\n",
    "    for dir_name, dirs, files in os.walk(input_path):\n",
    "        if len(files) > 0:\n",
    "            for input_file in (glob.glob(dir_name + '\\*.txt')):\n",
    "                file_path.append(input_file)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract patent ab infor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_collection_f(file):\n",
    "    ab_data =[]\n",
    "    ab_temp = []\n",
    "    for line in file.readlines():\n",
    "        if line[0:2] == 'AB':\n",
    "            is_in = 1\n",
    "            start_line = ([line[6:-1]])\n",
    "            ab_temp.append(start_line)\n",
    "        elif line[0:3] == '   ' and is_in == 1:\n",
    "            follow_line = line[3:-1]\n",
    "            ab_temp.append(start_line.append(follow_line))\n",
    "        else:\n",
    "            is_in = 0\n",
    "    for x in ab_temp:\n",
    "        if x != None  :\n",
    "            ab_data.append(x)\n",
    "    return ab_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract patent ti infor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ti_collection_f(file_path):\n",
    "    file = open(file_path, encoding='utf-8')\n",
    "    ti_collection=[]\n",
    "    for line in file.readlines():\n",
    "        if line.startswith('TI '):\n",
    "            ti_collection.append(str(line[3:-1]))\n",
    "    return ti_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## divide the ab infor to \"NOVELTY\" \"USE\" \"ADVANTAGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_mess_process_f(ab_data_slice):\n",
    "    ad_extract=[]\n",
    "    i = 0\n",
    "    if len(ab_data_slice)<3:\n",
    "        mark = 3 - len(ab_data_slice)\n",
    "        for x in ab_data_slice:\n",
    "            if x.strip().startswith('(') and 'NOVELTY' in x.strip():\n",
    "                ad_extract.append(x.strip().split(')')[1].strip())\n",
    "                ad_extract.append('miss')\n",
    "                ad_extract.append('miss')\n",
    "                continue\n",
    "            if x.strip().startswith('NOVELTY'):\n",
    "                ad_extract.append(x)\n",
    "            elif x.strip().startswith('USE'):\n",
    "                ad_extract.append(x)\n",
    "            elif x.strip().startswith('ADVANTAGE'):\n",
    "                ad_extract.append(x)\n",
    "            else:\n",
    "                ad_extract.append('miss')\n",
    "        for i_add in range(mark):\n",
    "            ad_extract.append('miss')\n",
    "    else:\n",
    "        for x in ab_data_slice:\n",
    "            if x.strip().startswith('(') and 'NOVELTY' in x.strip():\n",
    "                ad_extract.append(x.strip().split(')')[1].strip())\n",
    "                ad_extract.append('miss')\n",
    "                ad_extract.append('miss')\n",
    "                continue\n",
    "            if x.strip().startswith('NOVELTY'):\n",
    "                ad_extract.append(x)\n",
    "            elif x.strip().startswith('USE'):\n",
    "                ad_extract.append(x)\n",
    "            elif x.strip().startswith('ADVANTAGE'):\n",
    "                ad_extract.append(x)\n",
    "            else:\n",
    "                ad_extract.append('miss')\n",
    "            i += 1\n",
    "            if i == 3:\n",
    "                break\n",
    "    return ad_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## massive ab infor process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_process_f(ab_data):\n",
    "    ad_normmalize = []\n",
    "    for x in ab_data:\n",
    "        #print(len(x))\n",
    "        ad_normmalize.append(ab_mess_process_f(x))\n",
    "    return ad_normmalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createListCSV_ab(fileName, header=None, data_List=[]):\n",
    "    with open(fileName, 'w', newline='') as csvFile:\n",
    "        import csv\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        if header:\n",
    "            csvWriter.writerow(header)\n",
    "        for data in data_List:\n",
    "            for y in data:\n",
    "                csvWriter.writerow([y[0].split('- ')[-1],y[1].split('- ')[-1],y[2].split('- ')[-1]])\n",
    "        csvFile.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createListCSV_ti(fileName, header=None, data_List=[]):\n",
    "    with open(fileName, 'w', newline='') as csvFile:\n",
    "        import csv\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        if header:\n",
    "            csvWriter.writerow(header)\n",
    "        for data in data_List:\n",
    "            if  not isinstance(data,list):\n",
    "                csvWriter.writerow([data])\n",
    "        csvFile.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r''#input_path--where your file is stored such as \"C:\\Users\\bandk\\Desktop\\graphene_dii\\2012 \" a folder path\n",
    "otput_path = r''#output_path--where your file will be output in CSV such as \"C:\\Users\\bandk\\Desktop\\graphene_dii\\2012_out_ab \" a folder path\n",
    "file_path  =file_load_f(input_path)\n",
    "    ti_data =[]\n",
    "    for f in file_path:\n",
    "        file = open(f, 'r', encoding='UTF-8')\n",
    "        ab_data_temp = ab_process_f(ab_collection_f(file))\n",
    "        ab_data.append(ab_data_temp)\n",
    "        ti_data_temp = ti_collection_f(file)\n",
    "        ti_data = ti_data+ti_data_temp\n",
    "    header = ['NOVELTY','USE','ADVANTAGE']\n",
    "    createListCSV_ab(os.path.join(output_path,'ab_extract.csv'),header,ab_data) \n",
    "    header = ['TI']\n",
    "    createListCSV_ti(os.path.join(output_path,'ti_extract.csv'),header,ab_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
